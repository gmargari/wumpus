# Configuration file for the Wumpus search engine.
#
# All values set in this file can be overridden at the command line using
# ordinary command-line parameters, e.g., "bin/wumpus DIRECTORY=index-dir".

# This is the directory in which all index data are stored.
DIRECTORY = ./database/

# MAX_UPDATE_SPACE is the amount of RAM we give to the Lexicon class. Increase
# this if you want to have faster index construction. For TREC-like tasks,
# 256MB seems like a reasonable value.
MAX_UPDATE_SPACE = 256M

# Filters all messages sent to the logging facility. Log levels supported are:
#   1: LOG_DEBUG
#   2: LOG_OUTPUT
#   3: LOG_ERROR
# Setting LOG_LEVEL to 0 means allowing all logging. Setting it to 3 means no
# output at all.
LOG_LEVEL = 3

# Where are the log message written? In general, this is the file name of the
# log file. stdout and stderr have a special status.
LOG_FILE = stderr

# Set this to true if you want to have a read-only index.
READ_ONLY = false

# We refuse to index any files that are smaller than this.
MIN_FILE_SIZE = 8

# We refuse to index any files that are larger than this.
MAX_FILE_SIZE = 20000M

# Port that the HTTP server runs on (if started in WHS mode).
HTTP_PORT = 8080

# If this is greater than zero, we will have a TCP server accepting
# unauthenticated connections on the port specified. If less than zero,
# the TCP server will not be started.
TCP_PORT = -1

# Wumpus will accept connections from hosts that appear in this list. Wildcards
# ("*", "?") are supported.
TCP_ALLOWED = "127.0.0.1"

# Maximum number of active TCP connections at a time.
MAX_TCP_CONNECTIONS = 8

# QUERY_PROTOCOL can either be "MultiText" or "Wumpus". You should only set it
# to "MultiText" if you need to work with existing client software. Please note
# that index server and text server are the same within Wumpus.
QUERY_PROTOCOL = Wumpus

# By default, queries are processed by child processes with separate address
# space. If you need super-low latency for your queries, you should set this
# to "false" and use threads instead of processes, as the overhead associated
# with fork, waitpid, and copy-on-write easily causes a delay of a few
# milliseconds per query.
FORK_ON_QUERY = false

# This is the amount of memory we are willing to spend for processing a single
# query. If multiple queries are processed in parallel, memory consumption will
# exceed this limit.
MAX_QUERY_SPACE = 32M

# Defines whether extent lists that are stored in the cache are kept in
# compressed form or as raw 64-bit offsets (or 32-bit, depending on the
# offset width defined in config.h). A compressed index cache requires
# less memory, but query processing will be slower, because list fragments
# have to be decompressed at query time.
COMPRESSED_INDEXCACHE = true

# As soon as this portion of all postings in all CompactIndex instances is
# exceeded, we run the garbage collector.
GARBAGE_COLLECTION_THRESHOLD = 0.30

# When merging two or more sub-indices, we simultaneously run the garbage
# collector if the portion of garbage postings in all CompactIndex instances
# involved is greater than this.
ONTHEFLY_GARBAGE_COLLECTION_THRESHOLD = 0.10

# We use an internal username/password file in order to check whether @uid
# requests over TCP connections shall be accepted; this is the position of the
# password file. In addition to the password file, ordinary /etc/shadow
# authentication is provided. The password file given here should only be used
# if you don't want users to authenticate with their real Unix accounts.
PASSWORD_FILE = ./wumpus.passwd

# We support three different levels of stemming:
# - level 0: all stemming is performed at query time, maximimizing indexing
#            performance
# - level 1: some stemming is performed at indexing time; this means some
#            additional effort at query time: the query "$walking" will be
#            transformed into "walk"+"$walk", because "walk" is not stemmed
#            at indexing time
# - level 2: full stemming at indexing time (stemming results are cached to
#            achieve acceptable performance); note that stemming level 2
#            increases the size of the index by almost 100%
# - level 3: like level 2, but only stemmed forms are kept in the final index
STEMMING_LEVEL = 1

# Set this to TRUE if you want to index bigrams in addition to individual
# terms. Indexing bigrams greatly increases query processing performance
# for phrase queries.
BIGRAM_INDEXING = false

# If this is set to 1, Wumpus keeps additional information about term
# occurrences per document; these data can be used to speedup Okapi query
# performance and @docs queries. If it is set to 2, only per-document
# information (as well as "<doc>" and "</doc>" tags) will appear in the final
# index.
DOCUMENT_LEVEL_INDEXING = 0

# If this is set to true, the size of the index is drastically reduced
# (compared to simple document-level indexing), but we lose the ability to
# retrieve the text that corresponds to a given index extent. With position-
# less indexing, each posting consists of two components: the lower-most 5 bits
# contain the TF value, while the rest contains the DOCID.
POSITIONLESS_INDEXING = true

# The STATIC_LANGUAGE_MODEL variable specifies a file that contains the on-disk
# version of a LanguageModel instance. If defined, this language model will be
# used to perform pseudo-relevance feedback and indexing-time intra-document
# pruning.
STATIC_LANGUAGE_MODEL = null

# Tells us whether index files should be loaded into memory or kept on disk
# when initializing the system. ALL_INDICES_IN_MEMORY only works if the index
# is read-only.
ALL_INDICES_IN_MEMORY = false

# The TERABYTE_IN_MEMORY_INDEX variable is used to specify a pruned document-
# level index that can be loaded into memory in order to be used in conjunction
# with the TerabyteQuery (@bm25tera) class. The pruned in-memory index is
# crucial to Wumpus' high query processing performance on large text collections
# (< 30 ms/query on GOV2, for instance).
# TERABYTE_IN_MEMORY_INDEX =

# Defines the percentage of postings we keep during document-level
# (TerabyteLexicon) index construction. If TERABYTE_INTRA_DOCUMENT_PRUNING = p%,
# then for each document we only keep the top p% terms, ranked by their
# divergence from the collection-wide language model (defined by
# STATIC_LANGUAGE_MODEL).
TERABYTE_INTRADOC_PRUNING_LAMBDA = 1.0

# Defines the minimum number of postings we keep per document in document-
# centric static index pruning.
TERABYTE_INTRADOC_PRUNING_K = 1

# If this is true, then TerabyteLexicon builds document surrogates for all
# documents it sees. These surrogates can then be used to compare documents
# efficiently in TerabyteQuery, without having to access the plain text of
# the documents involved.
TERABYTE_SURROGATES = false

# Possible values for LEXICON_TYPE are:
# COMPRESSED_LEXICON, REALLOC_LEXICON, TERABYTE_LEXICON.
LEXICON_TYPE = COMPRESSED_LEXICON

# If ENABLE_XPATH is set to true, XML level tags are inserted into the index
# in order to distinguish between children and general descendants when
# executing XPath queries. The tags are of the form: "<level!N>", "</level!N>",
# where N is a positive number, indicating the nesting level.
ENABLE_XPATH = false

# XML_COMMENTS defines how to index comments in XML documents. There are three
# possible modes:
# - default: comments are indexed like normal XML, starting with an "<!--"
#     token and ending with an ">" token
# - plaintext: similar to the above case, but within the comment, '<' and '>'
#     are treated as whitespace characters and not as if they were XML tags
# - ignore: XML comments are indexed as a pair of tokens:
#     "<!-->" and "<!--/>"; searching for "<!-->".."</!-->" gives back the
#     extents of all proper XML comments
XML_COMMENTS = ignore

# Set this variable to true if you want to index character n-grams instead
# of proper tokens. For example, for n=5 the text "foo bar foobar" would be
# indexed as "foo_b oo_ba o_bar _bar_ bar_f ar_fo r_foo _foob fooba oobar".
# Note that n-gram tokenization is not fully supported by all query types.
# For example, while it works for descendants of RankedQuery, it does not
# work at all for GCLQuery.
USE_NGRAM_TOKENIZER = false

# The value of n to use for the n-gram tokenizer.
GRAM_SIZE_FOR_NGRAM_TOKENIZER = 5

# Wumpus supports five different update strategies that are used when dealing
# with dynamic text collections:
# - NO_MERGE
#     When RAM is full, a new sub-index is created; no merging is performed.
# - IMMEDIATE_MERGE
#     When RAM is full, the postings in memory are directly merged with the
#     on-disk postings
# - LOG_MERGE
#     A new sub-index is created on disk; if there is already an index of that
#     size, the two are merged; this is done recursively until there is only
#     one index of every size left.
# - SQRT_MERGE
#     Two on-disk indices are kept. Their size (relative to the value of
#     MAX_UPDATE_SPACE) is n^2 and n, respectively.
# - INPLACE
#     This is an in-place strategy, based on one of several possible implemen-
#     tations of an in-place-updatable index (class InPlaceIndex). It can be
#     very inefficient and is only for experimental purposes. Don't use it unless
#     you know exactly what you are doing. Merge update is highly recommended!
UPDATE_STRATEGY = LOG_MERGE

# If this is set to true, the index maintenance strategy is a hybrid strategy
# in which short lists are updated using a merge approach, while long lists are
# updated in-place, using an InPlaceIndex instance.
# Possible parameter values are:
#   OFF, CONTIGUOUS, NON_CONTIGUOUS, NON_CONTIGUOUS_APPEND.
HYBRID_INDEX_MAINTENANCE = OFF

# This configuration variable defines the threshold that is used to determine
# whether a list is updated in-place or not (number of postings).
LONG_LIST_THRESHOLD = 500000

# Employ partial flushing update strategy (write long lists exlusively, as long
# as possible)?
PARTIAL_FLUSH = false

# Depending on whether this is true or false, index maintenance operations,
# such as merging sub-indices and running the garbage collection, are either
# part of an update operation (synchronous) or executed in a separate process
# (asynchronous).
ASYNC_INDEX_MAINTENANCE = false

# Use MERGE_AT_EXIT to specify whether all CompactIndex instances shall be
# merged when the Index object is deleted. Even if MERGE_STRATEGY is not
# IMMEDIATE_MERGE, this will still force Wumpus to create one big index at
# the very end.
MERGE_AT_EXIT = true

# Maximum number of bytes transferred to/from disk per second. This
# configuration parameter is used to limit the performance impact caused
# by Wumpus indexing the file system.
MAX_IO_PER_SECOND = 20000000

# Tells Wumpus whether file system security restrictions (file permissions)
# have to be applied when a query is processed.
APPLY_SECURITY_RESTRICTIONS = true

# Maximum size for a sub-index ("index.???" file).
MAX_SUBINDEX_SIZE = 2048M

# For phoneme-based queries, we need to translate the query terms into phoneme
# sequences. This process is realized by calling the program given here.
TTP_DIR = /home/stu/devel/arise/phonesearch

# If requested, a cache of results to earlier GCL queries is maintained. The
# amount of memory consumed by this cache is unbounded, so be careful when
# giving one or more GCL expressions here. If more than one expression is
# given, separate by comma: EXP1, EXP2, ...
# Individual expressions are not allowed to contain commas (confuses the
# tokenizer).
CACHED_EXPRESSIONS = "<doc>".."</doc>"

# If not specified in the query, this expression is used as the container query
# in all document-centric retrieval functions.
DEFAULT_RETRIEVAL_SET = "<doc>".."</doc>"

# Directory under which files can be indexed. Any events coming in that refer
# to files outside the tree rooted at this directory will be ignored. This must
# be an absolute path. This configuration variable only applies to the wumpus
# IR system, not the file system search service.
BASE_DIRECTORY = /

# If MONITOR_FILESYSTEM is set to true, a daemon process will watch for file
# changes (fschange) and periodically scan the file system.
MONITOR_FILESYSTEM = false

# This is the file that we read file system change events from. It can either
# be a proc file (/proc/fschange) or some other file (probably a FIFO) that
# contains file system events.
FSCHANGE_FILE = /tmp/inotifyd

# This is the time between two consecutive exhaustive scans of the file
# system, given in minutes.
TIME_BETWEEN_FS_SCANS = 1440


########################################################################
# Macro definitions. Macros can be used to make your life easier when  #
# interacting with the search system directly. Macros are used in the  #
# following way:                                                       #
#                                                                      #
#   MACRO:DOCS = "<doc>".."</doc>"       (in the configuration file)   #
#   @gcl $(DOCS)>"wumpus"                (in the query)                #
#                                                                      #
# returns all documents containing the term "wumpus". :-)              #
########################################################################

MACRO:DOCS = ("<doc>".."</doc>")
MACRO:DOCNOS = ("</docno>".."</docno>")
MACRO:DOCUMENTS = ("<document!>".."</document!>")
MACRO:FILES = ("<file!>".."</file!>")
MACRO:TITLES = ("<title>".."</title>")
MACRO:WWF = with weights from


########################################################################
# Parameters for file system search ("bin/fssearch").                  #
########################################################################

# A list of all filesystems that may be indexed. If a filesystem does not
# appear in this list, we won't create an index for it and not even use
# an existing index for this filesystem.
INDEXABLE_FILESYSTEMS =  "/"


